{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6thDoiceJLgjQjxrRNVaw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Q1\n","\n","If we use X = np.array([[-2.69305227, 0.55617734, -2.43874732, 2.07026181], [ 1.46140931, 2.56987791, 1.40453353, 1.36132903], [-0.7035427 , 0.92223751, 0.36613864, -1.59524025], [ 1.20800429, -0.4637739 , 1.1106433 , 0.85284503], [-2.23840524, -0.84209178, -0.04810615, 1.53559851], [ 3.44829863, 2.13786731, 0.9661306 , -3.02757453], [ 4.19588081, 0.95286342, 0.16051249, 0.59197391], [ 0.1426253 , -1.25490369, 0.0986404 , 0.6355671 ], [ 0.27103178, 0.52906105, -0.64250317, -1.29833464], [-0.08165368, -0.87659034, -3.02019504, 1.0802352 ], [ 0.52249028, -1.72924316, 1.21902947, 1.38806363], [-0.23223567, -1.22051892, 2.88914811, -0.29774035], [-1.04524743, -1.27354275, -1.0832457 , 0.05064772], [ 0.51773799, -1.61353239, 0.13621013, -2.08071959]]) and y = np.array([2, 3, 0, 4, 3, 0, 3, 0, 1, 1, 4, 1, 2, 2]) to train a decision tree (with random_state = 146), what are the predictions for X_test = np.array([[ 0.59730683, -1.47388234, 0.19323579, 1.00210836], [ 1.40572379, 1.44596069, -0.72924456, -1.5125544 ], [-2.38342167, -0.36546006, 0.77207181, 2.69580243], [ 1.26963 , -1.74360923, 0.26511791, -2.56548327], [-3.7681268 , 1.71391718, -3.59390654, 3.78457425]])?"],"metadata":{"id":"gHeXxPK7azET"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","\n","X = np.array([[-2.69305227, 0.55617734, -2.43874732, 2.07026181], [ 1.46140931, 2.56987791, 1.40453353, 1.36132903], [-0.7035427 , 0.92223751, 0.36613864, -1.59524025], [ 1.20800429, -0.4637739 , 1.1106433 , 0.85284503], [-2.23840524, -0.84209178, -0.04810615, 1.53559851], [ 3.44829863, 2.13786731, 0.9661306 , -3.02757453], [ 4.19588081, 0.95286342, 0.16051249, 0.59197391], [ 0.1426253 , -1.25490369, 0.0986404 , 0.6355671 ], [ 0.27103178, 0.52906105, -0.64250317, -1.29833464], [-0.08165368, -0.87659034, -3.02019504, 1.0802352 ], [ 0.52249028, -1.72924316, 1.21902947, 1.38806363], [-0.23223567, -1.22051892, 2.88914811, -0.29774035], [-1.04524743, -1.27354275, -1.0832457 , 0.05064772], [ 0.51773799, -1.61353239, 0.13621013, -2.08071959]])\n","\n","y = np.array([2, 3, 0, 4, 3, 0, 3, 0, 1, 1, 4, 1, 2, 2])\n","\n","X_test = np.array([[ 0.59730683, -1.47388234, 0.19323579, 1.00210836], [ 1.40572379, 1.44596069, -0.72924456, -1.5125544 ], [-2.38342167, -0.36546006, 0.77207181, 2.69580243], [ 1.26963 , -1.74360923, 0.26511791, -2.56548327], [-3.7681268 , 1.71391718, -3.59390654, 3.78457425]])\n","\n","dt = RandomForestClassifier(random_state=146)\n","\n","dt.fit(X, y)\n","\n","dt.predict(X_test)"],"metadata":{"id":"ptLHaxg2wSe5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q2\n","\n","If we use X = np.array([[-2.69305227, 0.55617734, -2.43874732, 2.07026181], [ 1.46140931, 2.56987791, 1.40453353, 1.36132903], [-0.7035427 , 0.92223751, 0.36613864, -1.59524025], [ 1.20800429, -0.4637739 , 1.1106433 , 0.85284503], [-2.23840524, -0.84209178, -0.04810615, 1.53559851], [ 3.44829863, 2.13786731, 0.9661306 , -3.02757453], [ 4.19588081, 0.95286342, 0.16051249, 0.59197391], [ 0.1426253 , -1.25490369, 0.0986404 , 0.6355671 ], [ 0.27103178, 0.52906105, -0.64250317, -1.29833464], [-0.08165368, -0.87659034, -3.02019504, 1.0802352 ], [ 0.52249028, -1.72924316, 1.21902947, 1.38806363], [-0.23223567, -1.22051892, 2.88914811, -0.29774035], [-1.04524743, -1.27354275, -1.0832457 , 0.05064772], [ 0.51773799, -1.61353239, 0.13621013, -2.08071959]]) and y = np.array([2, 3, 0, 4, 3, 0, 3, 0, 1, 1, 4, 1, 2, 2]) to train KNN with K = 5, what are the predictions for X_test = np.array([[ 0.59730683, -1.47388234, 0.19323579, 1.00210836], [ 1.40572379, 1.44596069, -0.72924456, -1.5125544 ], [-2.38342167, -0.36546006, 0.77207181, 2.69580243], [ 1.26963 , -1.74360923, 0.26511791, -2.56548327], [-3.7681268 , 1.71391718, -3.59390654, 3.78457425]])?"],"metadata":{"id":"0GMkJM_7wXux"}},{"cell_type":"code","source":["X = np.array([[-2.69305227, 0.55617734, -2.43874732, 2.07026181], [ 1.46140931, 2.56987791, 1.40453353, 1.36132903], [-0.7035427 , 0.92223751, 0.36613864, -1.59524025], [ 1.20800429, -0.4637739 , 1.1106433 , 0.85284503], [-2.23840524, -0.84209178, -0.04810615, 1.53559851], [ 3.44829863, 2.13786731, 0.9661306 , -3.02757453], [ 4.19588081, 0.95286342, 0.16051249, 0.59197391], [ 0.1426253 , -1.25490369, 0.0986404 , 0.6355671 ], [ 0.27103178, 0.52906105, -0.64250317, -1.29833464], [-0.08165368, -0.87659034, -3.02019504, 1.0802352 ], [ 0.52249028, -1.72924316, 1.21902947, 1.38806363], [-0.23223567, -1.22051892, 2.88914811, -0.29774035], [-1.04524743, -1.27354275, -1.0832457 , 0.05064772], [ 0.51773799, -1.61353239, 0.13621013, -2.08071959]])\n","\n","y = np.array([2, 3, 0, 4, 3, 0, 3, 0, 1, 1, 4, 1, 2, 2])\n","\n","X_test = np.array([[ 0.59730683, -1.47388234, 0.19323579, 1.00210836], [ 1.40572379, 1.44596069, -0.72924456, -1.5125544 ], [-2.38342167, -0.36546006, 0.77207181, 2.69580243], [ 1.26963 , -1.74360923, 0.26511791, -2.56548327], [-3.7681268 , 1.71391718, -3.59390654, 3.78457425]])\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","clf=KNeighborsClassifier(n_neighbors=5)\n","clf=clf.fit(X,y)\n","clf.predict(X_test)\n","\n","array([4, 0, 2, 0, 2])"],"metadata":{"id":"YNZy7wm2wd-e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import pandas as pd\n","import io\n","import requests\n","\n","# dataset1 (Data1)\n","df_url = 'https://raw.githubusercontent.com/akmand/datasets/master/openintro/bdims.csv'\n","url_content = requests.get(df_url, verify=False).content\n","data1 = pd.read_csv(io.StringIO(url_content.decode('utf-8')))\n","\n","# dataset2 (Data2)\n","df_url = 'https://raw.githubusercontent.com/akmand/datasets/main/baseball.csv'\n","url_content = requests.get(df_url, verify=False).content\n","data2 = pd.read_csv(io.StringIO(url_content.decode('utf-8')))  \n","\n","# dataset3 (Data3)\n","df_url = 'https://raw.githubusercontent.com/akmand/datasets/main/cdc.csv'\n","url_content = requests.get(df_url, verify=False).content\n","data3 = pd.read_csv(io.StringIO(url_content.decode('utf-8')))\n","\n","\n","Q3\n","\n","\n","If data1.sample(n=91,random_state=24) is your data where 'sex' is target, what would be the out-of-bag score for baseline random forest model with 97 trees and random_state = 24?\n","\n","\n","0.8797989010989011\n","\n","0.9164989010989011\n","\n","0.9010989010989011\n","\n","0.89890109814250"],"metadata":{"id":"6ZkacwL9wrv3"}},{"cell_type":"code","source":["sample1 = data1.sample(n=91,random_state=24)\n","sample1.isna().sum()\n","X = sample1.drop(\"sex\", axis=1)\n","y = sample1[['sex']]\n","from sklearn.ensemble import *\n","clf = RandomForestClassifier(n_estimators=97, random_state=24,oob_score=True)\n","\n","clf.fit(X,y)\n","clf.oob_score_"],"metadata":{"id":"vaeu-vn1w125"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Null values in Data1:\")\n","print(data1.isnull().sum())\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","\n","# Sample the data\n","sampled_data = data1.sample(n=91, random_state=24)\n","\n","# Separate features (X) and target (y)\n","X = sampled_data.drop('sex', axis=1)  # Assuming 'sex' is the target column\n","y = sampled_data['sex']\n","\n","# Create and train the Random Forest model\n","rf_model = RandomForestClassifier(n_estimators=97, oob_score=True, random_state=24)\n","rf_model.fit(X, y)\n","\n","# Get the out-of-bag score\n","oob_score = rf_model.oob_score_\n","\n","# Print the result\n","print(f\"Out-of-bag score: {oob_score}\")"],"metadata":{"id":"r1WSBqeow3wo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q4\n","\n","\n","You will be using the data1 dataset for this question. Using the features ['bia.di', 'bii.di', 'bit.di', 'che.de', 'elb.di', 'wri.di', 'kne.di', 'ank.di'], create a RandomForest model to predict a person's sex. Split the data into training (80%) and testing (20%) sets using random_state=128. Train the RandomForest model with n_estimators=50, max_depth=7, and random_state=128.\n","\n","Print the score for testing data and oob score for the model.\n","\n","1.   List item\n","2.   List item\n","\n"],"metadata":{"id":"d31iFJP-w_Ui"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","features = ['bia.di', 'bii.di', 'bit.di', 'che.de', 'elb.di', 'wri.di', 'kne.di', 'ank.di']\n","X = data1[features]\n","y = data1['sex']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=128)\n","\n","rfc = RandomForestClassifier(n_estimators=50, max_depth=7, random_state=128, oob_score=True)\n","\n","rfc.fit(X_train, y_train)\n","\n","y_pred = rfc.predict(X_test)\n","\n","rfc.oob_score_\n","0.928395061728395\n","\n","accuracy_score(y_test, y_pred)\n","0.9509803921568627"],"metadata":{"id":"U0SwGVaxxDdE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q5\n","\n","If data3.sample(n=2861,random_state=417) is your data and you apply one hot encoding on 'genhlth' feature of sample data. findout the data at index 1686 and match with following option.\n","\n","A) [[1, 1, 1, 63, 132, 125, 49, 'f', 0, 0, 0, 0, 1]]\n","\n","B) [[1, 4, 1, 63, 132, 125, 49, 'f', 0, 0, 0, 0, 1]]\n","\n","C) [[1, 1, 1, 63, 115, 125, 49, 'f', 0, 1, 0, 0, 1]]"],"metadata":{"id":"vbkGIWGCxF91"}},{"cell_type":"code","source":["data3_new = data3.sample(n=2861,random_state=417)\n","\n","one_hot_data3 = pd.get_dummies(data3_new.genhlth)\n","\n","data3_new = data3_new.join(one_hot_data3)\n","\n","data3_new.iloc[1686]\n","\n","# A) [[1, 1, 1, 63, 132, 125, 49, 'f', 0, 0, 0, 0, 1]]"],"metadata":{"id":"Qu9GhYIXxJc5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q6\n","\n","If data3.sample(n=2803,random_state=130) is your data and you apply providing mapping ('good':6, 'very good':11, 'excellent':22, 'fair':32, 'poor':49) on 'genhlth' feature of sample data. findout the data at index 1153 and match with following option.\n","\n","A) [[32, 1, 1, 0, 74, 230, 200, 66, 'm']]\n","B) [[11, 0, 1, 0, 71, 250, 220, 32, 'm']]\n","C) [[6, 0, 1, 1, 77, 235, 235, 27, 'm']]"],"metadata":{"id":"DRUg4kiKxOhW"}},{"cell_type":"code","source":["data3_3 = data3.sample(n=2803,random_state=130)\n","\n","mapping = {'good':6, 'very good':11, 'excellent':22, 'fair':32, 'poor':49}\n","\n","data3_3.genhlth = data3_3.genhlth.map(mapping)\n","\n","data3_3.iloc[1153]\n","\n","# B) [[11, 0, 1, 0, 71, 250, 220, 32, 'm']]"],"metadata":{"id":"ofbX-sBRxTzc"},"execution_count":null,"outputs":[]}]}